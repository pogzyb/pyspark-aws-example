{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dill\n",
    "import os\n",
    "\n",
    "from typing import List, Tuple, Any, Dict\n",
    "\n",
    "# import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from scipy import stats\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Create dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in sample_set.csv...\n",
      "Modifying target variable \"Duration\" => \"duration_log1p\"...\n",
      "Removing unreasonably long rides (greater than 1.5 hours) ...\n",
      "Removing \"Unknown\" Member type rows...\n",
      "Cleaned Rides Dataset (rows, columns): (666134, 7)\n"
     ]
    }
   ],
   "source": [
    "seed = 33\n",
    "row_limit = 700000 \n",
    "data_dir = '../data/'\n",
    "\n",
    "rides_use_columns = [\n",
    "    'Duration', 'Start date', 'End date', 'Start station number', 'End station number', 'Member type'\n",
    "]\n",
    "dataset = pd.DataFrame()\n",
    "for file in os.listdir(os.path.join(data_dir, 'rides')):\n",
    "    if file.startswith('sample_set'):\n",
    "        print(f'Reading in {file}...')\n",
    "        tmp = pd.read_csv(\n",
    "            os.path.join(data_dir, 'rides', file), \n",
    "            nrows=row_limit, \n",
    "            usecols=rides_use_columns\n",
    "        )\n",
    "        dataset = pd.concat([dataset, tmp], sort=False, ignore_index=True)\n",
    "\n",
    "stations_use_columns = [\n",
    "    'TERMINAL_NUMBER', 'LONGITUDE', 'LATITUDE', 'NUMBER_OF_EMPTY_DOCKS', 'NUMBER_OF_BIKES'\n",
    "]\n",
    "stations = pd.read_csv(\n",
    "    os.path.join(data_dir, 'stations/capbs_stations.csv'),\n",
    "    usecols=stations_use_columns\n",
    ")\n",
    "\n",
    "print(f'Modifying target variable \"Duration\" => \"duration_log1p\"...')\n",
    "dataset['duration_log1p'] = np.log1p(dataset.Duration)\n",
    "\n",
    "hours = 1.5\n",
    "mins = 2.5\n",
    "print(f'Removing unreasonably long rides (greater than {hours} hours) ...')\n",
    "dataset = dataset.loc[(dataset['Duration'] <= (60 * 60 * hours)) & (dataset['Duration'] >= (60 * mins)), :]\n",
    "\n",
    "print(f'Removing \"Unknown\" Member type rows...')\n",
    "dataset = dataset.loc[(dataset['Member type'] != 'Unknown'), :]\n",
    "\n",
    "dataset = dataset.loc[~(dataset['Start station number'] == 31008) &\n",
    "                       ~(dataset['Start station number'] == 32051) &\n",
    "                       ~(dataset['Start station number'] == 32034), :]\n",
    "\n",
    "dataset = dataset.loc[~(dataset['End station number'] == 31008) &\n",
    "                       ~(dataset['End station number'] == 32051) &\n",
    "                       ~(dataset['End station number'] == 32034), :]\n",
    "\n",
    "print(f'Cleaned Rides Dataset (rows, columns): {dataset.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stations information (rows, columns): (571, 5)\n",
      "Merged Stations information into Rides dataset.\n"
     ]
    }
   ],
   "source": [
    "print(f'Stations information (rows, columns): {stations.shape}')\n",
    "stations.loc[:,'station_total_bikes'] = stations.loc[:,'NUMBER_OF_BIKES'] + stations.loc[:,'NUMBER_OF_EMPTY_DOCKS']\n",
    "stations_start = stations.loc[:, ['station_total_bikes', 'LATITUDE', 'LONGITUDE', 'TERMINAL_NUMBER']]\n",
    "stations_start.columns = ['station_total_bikes', 'start_station_lat', 'start_station_long', 'Start station number']\n",
    "\n",
    "stations_end = stations.loc[:, ['LATITUDE', 'LONGITUDE', 'TERMINAL_NUMBER']]\n",
    "stations_end.columns = ['end_station_lat', 'end_station_long', 'End station number']\n",
    "\n",
    "dataset = dataset.merge(stations_start, on='Start station number', how='left', sort=False)\n",
    "dataset = dataset.merge(stations_end, on='End station number', how='left', sort=False)\n",
    "print(f'Merged Stations information into Rides dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset (rows, columns): (446310, 12)\n",
      "Testset (rows, columns): (219824, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Start date</th>\n",
       "      <th>End date</th>\n",
       "      <th>Start station number</th>\n",
       "      <th>End station number</th>\n",
       "      <th>Member type</th>\n",
       "      <th>duration_log1p</th>\n",
       "      <th>station_total_bikes</th>\n",
       "      <th>start_station_lat</th>\n",
       "      <th>start_station_long</th>\n",
       "      <th>end_station_lat</th>\n",
       "      <th>end_station_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1012</td>\n",
       "      <td>2010-09-20 11:27:04</td>\n",
       "      <td>2010-09-20 11:43:56</td>\n",
       "      <td>31208</td>\n",
       "      <td>31108</td>\n",
       "      <td>Member</td>\n",
       "      <td>6.920672</td>\n",
       "      <td>16</td>\n",
       "      <td>38.876300</td>\n",
       "      <td>-77.003700</td>\n",
       "      <td>38.876700</td>\n",
       "      <td>-77.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1413</td>\n",
       "      <td>2010-09-20 12:10:43</td>\n",
       "      <td>2010-09-20 12:34:17</td>\n",
       "      <td>31100</td>\n",
       "      <td>31201</td>\n",
       "      <td>Member</td>\n",
       "      <td>7.254178</td>\n",
       "      <td>15</td>\n",
       "      <td>38.900300</td>\n",
       "      <td>-77.042900</td>\n",
       "      <td>38.909850</td>\n",
       "      <td>-77.034438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1659</td>\n",
       "      <td>2010-09-20 12:16:36</td>\n",
       "      <td>2010-09-20 12:44:15</td>\n",
       "      <td>31111</td>\n",
       "      <td>31208</td>\n",
       "      <td>Member</td>\n",
       "      <td>7.414573</td>\n",
       "      <td>14</td>\n",
       "      <td>38.917200</td>\n",
       "      <td>-77.025900</td>\n",
       "      <td>38.876300</td>\n",
       "      <td>-77.003700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2988</td>\n",
       "      <td>2010-09-20 12:41:37</td>\n",
       "      <td>2010-09-20 13:31:25</td>\n",
       "      <td>31206</td>\n",
       "      <td>31603</td>\n",
       "      <td>Member</td>\n",
       "      <td>8.002694</td>\n",
       "      <td>11</td>\n",
       "      <td>38.895200</td>\n",
       "      <td>-77.043600</td>\n",
       "      <td>38.905700</td>\n",
       "      <td>-77.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>277</td>\n",
       "      <td>2010-09-20 13:30:21</td>\n",
       "      <td>2010-09-20 13:34:58</td>\n",
       "      <td>31106</td>\n",
       "      <td>31104</td>\n",
       "      <td>Member</td>\n",
       "      <td>5.627621</td>\n",
       "      <td>23</td>\n",
       "      <td>38.923203</td>\n",
       "      <td>-77.047637</td>\n",
       "      <td>38.922925</td>\n",
       "      <td>-77.042581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Duration           Start date             End date  Start station number  \\\n",
       "0       1012  2010-09-20 11:27:04  2010-09-20 11:43:56                 31208   \n",
       "2       1413  2010-09-20 12:10:43  2010-09-20 12:34:17                 31100   \n",
       "3       1659  2010-09-20 12:16:36  2010-09-20 12:44:15                 31111   \n",
       "7       2988  2010-09-20 12:41:37  2010-09-20 13:31:25                 31206   \n",
       "10       277  2010-09-20 13:30:21  2010-09-20 13:34:58                 31106   \n",
       "\n",
       "    End station number Member type  duration_log1p  station_total_bikes  \\\n",
       "0                31108      Member        6.920672                   16   \n",
       "2                31201      Member        7.254178                   15   \n",
       "3                31208      Member        7.414573                   14   \n",
       "7                31603      Member        8.002694                   11   \n",
       "10               31104      Member        5.627621                   23   \n",
       "\n",
       "    start_station_lat  start_station_long  end_station_lat  end_station_long  \n",
       "0           38.876300          -77.003700        38.876700        -77.017800  \n",
       "2           38.900300          -77.042900        38.909850        -77.034438  \n",
       "3           38.917200          -77.025900        38.876300        -77.003700  \n",
       "7           38.895200          -77.043600        38.905700        -77.005600  \n",
       "10          38.923203          -77.047637        38.922925        -77.042581  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = dataset.sample(frac=0.33, random_state=seed)\n",
    "dataset.drop(testset.index, inplace=True)\n",
    "print(f'Trainset (rows, columns): {dataset.shape}')\n",
    "print(f'Testset (rows, columns): {testset.shape}')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii Prep features\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# station_metrics = {}\n",
    "\n",
    "# def get_distance(c1_lat_long: Tuple[float, float], c2_lat_long: Tuple[float, float]) -> float:\n",
    "#     return np.sqrt((c1_lat_long[0] - c2_lat_long[0])**2 + (c1_lat_long[1] - c2_lat_long[1])**2)\n",
    "\n",
    "# def get_station_city_location(station_num: int):\n",
    "#     return\n",
    "\n",
    "# def get_average_station_distance(station_num: int):\n",
    "    \n",
    "#     return\n",
    "\n",
    "# def get_median_station_duration(station_num: int):\n",
    "#     return\n",
    "\n",
    "# for row in stations_start.iterrows():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords = np.vstack((\n",
    "#     dataset.loc[:,['start_station_long', 'start_station_lat']].values,\n",
    "#     dataset.loc[:,['end_station_long', 'end_station_lat']].values\n",
    "# ))\n",
    "\n",
    "# dataset['week_of_year'] = dataset['Start date'].apply(lambda x: x.weekofyear)\n",
    "# dataset['day_of_week'] = dataset['Start date'].apply(lambda x: x.dayofweek)\n",
    "# dataset['hour'] = dataset['Start date'].apply(lambda x: x.hour)\n",
    "\n",
    "# ride_scaler = StandardScaler()\n",
    "# ride_scaler.fit(dataset.loc[:,['start_station_long', 'start_station_lat', 'hour', 'day_of_week', 'week_of_year']])\n",
    "\n",
    "# ride_scaler.fit(dataset.loc[:,['start_station_long', 'start_station_lat', 'hour', 'day_of_week', 'week_of_year']])\n",
    "\n",
    "\n",
    "# kmeans = MiniBatchKMeans(n_clusters=50, batch_size=100000).fit(rides_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.loc[:, 'ride_cluster'] = kmeans.predict(dataset[['start_station_long', 'start_station_lat']]).astype('str')\n",
    "# testset.loc[:, 'ride_cluster'] = kmeans.predict(testset[['start_station_long', 'start_station_lat']]).astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Pipeline\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareRiders(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._final_columns = None\n",
    "    \n",
    "    def _make_time_cyclical(self, feature: pd.Series, time_divisor: int) -> Tuple[np.array, np.array]:\n",
    "        sin = np.sin(2 * np.pi * feature / time_divisor)\n",
    "        cos = np.cos(2 * np.pi * feature / time_divisor)\n",
    "        return (sin, cos)\n",
    "        \n",
    "    def transform(self, Xt: pd.DataFrame) -> np.array:\n",
    "        print(f'Initial dataset shape: {Xt.shape}')\n",
    "        \n",
    "        # convert to date type\n",
    "        Xt['Start date'] = pd.to_datetime(Xt['Start date'])\n",
    "        \n",
    "        # separate out date features\n",
    "        Xt['day_of_week'] = Xt['Start date'].apply(lambda x: x.dayofweek)\n",
    "        Xt['week_of_year'] = Xt['Start date'].apply(lambda x: x.weekofyear)\n",
    "        Xt['month'] = Xt['Start date'].apply(lambda x: x.month)\n",
    "        Xt['minute'] = Xt['Start date'].apply(lambda x: x.minute)\n",
    "        Xt['hour'] = Xt['Start date'].apply(lambda x: x.hour)\n",
    "        Xt.drop(['Start date'], axis=1, inplace=True)\n",
    "        \n",
    "        # make date features cyclical\n",
    "        Xt['sin_day_of_week'], Xt['cos_day_of_week'] = self._make_time_cyclical(Xt['day_of_week'], 7)\n",
    "        Xt['sin_week_of_year'], Xt['cos_week_of_year'] = self._make_time_cyclical(Xt['week_of_year'], 53)\n",
    "        Xt['sin_month'], Xt['cos_month'] = self._make_time_cyclical(Xt['month']-1, 12)\n",
    "        Xt['sin_minute'], Xt['cos_minute'] = self._make_time_cyclical(Xt['minute'], 60)\n",
    "        Xt['sin_hour'], Xt['cos_hour'] = self._make_time_cyclical(Xt['hour'], 24)\n",
    "        \n",
    "        # custom transformations\n",
    "        Xt['hour_and_day_of_week'] = Xt['hour'].astype(str) + '_' + Xt['day_of_week'].astype(str)\n",
    "        Xt['member_type_and_day_of_week'] = Xt['Member type'].astype(str) + '_' + Xt['day_of_week'].astype(str)\n",
    "        \n",
    "        Xt.drop(['day_of_week', 'week_of_year', 'month', 'minute', 'hour'], axis=1, inplace=True)\n",
    "        Xt.drop(['Start station number'], axis=1, inplace=True)\n",
    "        \n",
    "        # transform categorical features\n",
    "        Xt = pd.get_dummies(Xt)\n",
    "        \n",
    "        # save final columns\n",
    "        if not self._final_columns:\n",
    "            self._final_columns = Xt.columns.tolist()\n",
    "        else:\n",
    "            not_in_training = list(set(Xt.columns.tolist()) - set(self._final_columns))\n",
    "            not_in_testing = list(set(self._final_columns) - set(Xt.columns.tolist()))\n",
    "            if not_in_training:\n",
    "                Xt.drop(not_in_training, axis=1, inplace=True)\n",
    "            if not_in_testing:\n",
    "                empties = dict.fromkeys(not_in_testing, 0)\n",
    "                Xt = Xt.assign(**empties)\n",
    "        print(f'Prepared dataset shape: {Xt.shape}')\n",
    "        return Xt.values\n",
    "    \n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools for plotting residuals\n",
    "def fourPlot(y_true: np.array, y_pred: np.array) -> None:\n",
    "    plt.figure(figsize=(15,10));\n",
    "    residuals = y_true - y_pred\n",
    "    # Histogram\n",
    "    plt.subplot(2,2,1);\n",
    "    plt.title(\"Histogram\");\n",
    "    plt.hist(residuals, alpha=0.5);\n",
    "    # Lag plot\n",
    "    plt.subplot(2,2,2);\n",
    "    plt.title(\"Lag Plot\");\n",
    "    lag = residuals.copy()\n",
    "    lag = lag[:-1]\n",
    "    current = residuals[1:]\n",
    "    sns.regplot(current, lag, fit_reg=False);\n",
    "    # QQ plot\n",
    "    plt.subplot(2,2,3);\n",
    "    plt.title(\"QQ Plot\");\n",
    "    qntls, xr = stats.probplot(residuals, fit=False)\n",
    "    sns.regplot(xr, qntls, ci=0);\n",
    "    # Run Sequence plot\n",
    "    plt.subplot(2,2,4);\n",
    "    plt.title(\"Run Sequence\");\n",
    "    sns.regplot(np.arange(len(residuals)), residuals, ci=0);\n",
    "    return\n",
    "\n",
    "# Custom scoring function\n",
    "def rmse_func(y_true: np.array, y_pred: np.array) -> float:\n",
    "    return mean_squared_error(y_true, y_pred) ** 0.5\n",
    "\n",
    "rmse_scorer = make_scorer(rmse_func, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. RandomizedSearchCV\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_randomsearch_with_pipe(\n",
    "        regressors: list, \n",
    "        params_map: dict, \n",
    "        cv: KFold,\n",
    "        df_columns: list,\n",
    "        scorer: callable,\n",
    "        x1: pd.DataFrame, \n",
    "        x2: pd.DataFrame, \n",
    "        y1: np.array, \n",
    "        y2: np.array\n",
    ") -> None:\n",
    "        \n",
    "    for reg, model in regressors:\n",
    "        params = params_map[reg]\n",
    "        pipe = Pipeline(\n",
    "            steps=[\n",
    "                (\n",
    "                    'prepare', \n",
    "                    PrepareRiders()\n",
    "                ),\n",
    "                (\n",
    "                    'scaler',\n",
    "                    StandardScaler()\n",
    "                ),\n",
    "                (\n",
    "                    reg, \n",
    "                    model(random_state=33)\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        grid = GridSearchCV(estimator=pipe, param_grid=params, scoring=scorer, cv=kf, n_jobs=2)\n",
    "        grid.fit(x1, y1)\n",
    "        print(f'Best Params:\\n{grid.best_params_}')\n",
    "        \n",
    "        # top_features = pd.Series(est.feature_importances_, index=prep._final_columns).sort_values(ascending=False).head(10)\n",
    "        \n",
    "        test_preds = grid.predict(x2)\n",
    "        testset_raw_score = np.sqrt(mean_squared_error(y2, test_preds))\n",
    "        testset_rmse_expm1 = np.sqrt(mean_squared_error(np.expm1(y2), np.expm1(test_preds)))\n",
    "        context_error = f'This model is off by ~{round(testset_rmse_expm1 / 60, 2)} minutes'\n",
    "        print(f'Model: {reg}\\nRMSE: {testset_raw_score}\\nRMSE EXPM1: {testset_rmse_expm1}\\nCONTEXT: {context_error}\\nPARAMS: {grid.best_params_}')\n",
    "        # check residuals with the \"Four Plot\"\n",
    "#         print(f'Context error: {context_error}')\n",
    "        \n",
    "        fourPlot(y2, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and testing variables\n",
    "\n",
    "use_columns = [\n",
    "    'Start date',\n",
    "    'Member type', \n",
    "    'Start station number', \n",
    "    'start_station_lat', \n",
    "    'start_station_long', \n",
    "#     'ride_cluster'\n",
    "]\n",
    "\n",
    "x1, y1 = dataset.loc[:, use_columns], dataset.duration_log1p\n",
    "x2, y2 = testset.loc[:, use_columns], testset.duration_log1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_map = {\n",
    "    'rf': {\n",
    "        'rf__max_depth': [3],\n",
    "        'rf__n_estimators': [300],\n",
    "        'rf__min_samples_split': [2],\n",
    "        'rf__min_samples_leaf': [1],\n",
    "        'rf__min_weight_fraction_leaf': [0.0],\n",
    "    },\n",
    "    'gb': {\n",
    "        'gb__max_depth': [3, 5],\n",
    "        'gb__n_estimators': [150, 300],\n",
    "        'gb__learning_rate': [0.1],\n",
    "    },\n",
    "    'ls': {\n",
    "        'ls__alpha': [1.0, 0.5, 0.1],\n",
    "        'ls__max_iter': [1000, 1500]\n",
    "    },\n",
    "    'rd': {\n",
    "        'rd__alpha': [1.0],\n",
    "        'rd__max_iter': [None]\n",
    "    },\n",
    "    'lg': {\n",
    "        'lg__n_estimators': [100, 150]\n",
    "    }\n",
    "}\n",
    "\n",
    "regressors = [\n",
    "    ('rf', RandomForestRegressor),\n",
    "#     ('gb', GradientBoostingRegressor),\n",
    "#     ('ls', Lasso),\n",
    "#     ('rd', Ridge),\n",
    "#     ('lg', lgb.LGBMRegressor)\n",
    "]\n",
    "\n",
    "kf = KFold(n_splits=7, shuffle=True, random_state=33)\n",
    "\n",
    "run_randomsearch_with_pipe(\n",
    "    regressors=regressors, \n",
    "    params_map=params_map,\n",
    "    df_columns=use_columns,\n",
    "    scorer=rmse_scorer,\n",
    "    cv=kf,\n",
    "    x1=x1,\n",
    "    x2=x2,\n",
    "    y1=y1,\n",
    "    y2=y2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM performs the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
