{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import RandomForestRegressor, GeneralizedLinearRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1191585 rows in the dataset\n",
      "+--------+-------------------+--------------------+-----------+\n",
      "|Duration|         Start date|Start station number|Member type|\n",
      "+--------+-------------------+--------------------+-----------+\n",
      "|    2762|2017-07-01 00:01:09|               31289|     Casual|\n",
      "|    2763|2017-07-01 00:01:24|               31289|     Casual|\n",
      "|     690|2017-07-01 00:01:45|               31122|     Member|\n",
      "|     134|2017-07-01 00:01:46|               31201|     Member|\n",
      "|     587|2017-07-01 00:02:05|               31099|     Casual|\n",
      "+--------+-------------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"ML-Example\").getOrCreate()\n",
    "df = spark.read.csv(\"/home/jovyan/data/rides/2017Q3-capitalbikeshare-tripdata.csv\", header=True)\n",
    "df = df.select(['Duration', 'Start date', 'Start station number', 'Member type'])\n",
    "df = df.withColumn('Start station number', df['Start station number'].cast(IntegerType()))\n",
    "print(f'There are {df.count()} rows in the dataset')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 571 rows in the stations\n",
      "+-----------------+------------------+--------------------+\n",
      "|start_station_lat|start_station_long|Start station number|\n",
      "+-----------------+------------------+--------------------+\n",
      "|        39.083673|        -77.149162|               32017|\n",
      "|        39.123513|         -77.15741|               32018|\n",
      "|        38.990249|         -77.02935|               32019|\n",
      "|        39.107709|        -77.152072|               32020|\n",
      "|        38.982456|        -77.091991|               32021|\n",
      "+-----------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stations = spark.read.csv(\"/home/jovyan/data/stations/*\", header=True)\n",
    "print(f'There are {stations.count()} rows in the stations')\n",
    "stations = stations.withColumnRenamed('LATITUDE', 'start_station_lat')\n",
    "stations = stations.withColumnRenamed('LONGITUDE', 'start_station_long')\n",
    "stations = stations.withColumn('Start station number', stations['TERMINAL_NUMBER'].cast(IntegerType()))\n",
    "stations = stations.select(['start_station_lat', 'start_station_long', 'Start station number'])\n",
    "stations.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rides longer than 1.5 hours\n",
    "one_and_a_half_hours = 60 * 60 * 1.5\n",
    "df = df.filter(df['Duration'] <= one_and_a_half_hours)\n",
    "# remove rides shorter than 3 minutes\n",
    "three_minutes = 60 * 3\n",
    "df = df.filter(df['Duration'] >= three_minutes)\n",
    "# remove unknown 'Member type's\n",
    "df = df.filter(~(df['Member type'] == 'Unknown'))\n",
    "\n",
    "# remove non-existent stations\n",
    "df = df.filter(~(df['Start station number'] == 31008) & ~(df['Start station number'] == 32051) & ~(df['Start station number'] == 32034))\n",
    "\n",
    "# make label/target feature\n",
    "df = df.withColumn('label', F.log1p(df.Duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete dataset has 1116875 rows\n",
      "+--------------------+--------+-------------------+-----------+-----------------+-----------------+------------------+\n",
      "|Start station number|Duration|         Start date|Member type|            label|start_station_lat|start_station_long|\n",
      "+--------------------+--------+-------------------+-----------+-----------------+-----------------+------------------+\n",
      "|               31289|    2762|2017-07-01 00:01:09|     Casual|7.924072324923417|        38.890544|        -77.049379|\n",
      "|               31289|    2763|2017-07-01 00:01:24|     Casual| 7.92443418488756|        38.890544|        -77.049379|\n",
      "|               31122|     690|2017-07-01 00:01:45|     Member| 6.53813982376767|        38.928893|         -77.03625|\n",
      "|               31099|     587|2017-07-01 00:02:05|     Casual|6.376726947898627|        38.813485|        -77.049468|\n",
      "|               31099|     586|2017-07-01 00:02:06|     Casual|6.375024819828097|        38.813485|        -77.049468|\n",
      "+--------------------+--------+-------------------+-----------+-----------------+-----------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.join(stations, on='Start station number', how='left')\n",
    "df = df.withColumn('start_station_long', df['start_station_long'].cast(DoubleType()))\n",
    "df = df.withColumn('start_station_lat', df['start_station_lat'].cast(DoubleType()))\n",
    "print(f'Complete dataset has {df.count()} rows')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. EDA \n",
    "Exploratory Data Analysis is covered in the `bike-share-eda.ipynb` notebook\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Prediction Pipeline with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Start date\", F.to_timestamp('Start date', 'yyyy-MM-dd HH:mm:ss'))\n",
    "df = df.withColumn(\"day_of_week\", F.dayofweek(\"Start date\"))\n",
    "df = df.withColumn(\"week_of_year\", F.weekofyear(\"Start date\"))\n",
    "df = df.withColumn(\"month\", F.month(\"Start date\"))\n",
    "df = df.withColumn(\"minute\", F.minute(\"Start date\"))\n",
    "df = df.withColumn(\"hour\", F.hour(\"Start date\"))\n",
    "\n",
    "pi = 3.141592653589793\n",
    "\n",
    "df = df.withColumn('sin_day_of_week', F.sin(2 * pi * df['day_of_week'] / 7))\n",
    "df = df.withColumn('sin_week_of_year', F.sin(2 * pi * df['week_of_year'] / 53))\n",
    "df = df.withColumn('sin_month', F.sin(2 * pi * (df['month'] - 1) / 12))\n",
    "df = df.withColumn('sin_minute', F.sin(2 * pi * df['minute'] / 60))\n",
    "df = df.withColumn('sin_hour', F.sin(2 * pi * df['hour'] / 24))\n",
    "\n",
    "df = df.withColumn('cos_day_of_week', F.cos(2 * pi * df['day_of_week'] / 7))\n",
    "df = df.withColumn('cos_week_of_year', F.cos(2 * pi * df['week_of_year'] / 53))\n",
    "df = df.withColumn('cos_month', F.cos(2 * pi * (df['month'] - 1) / 12))\n",
    "df = df.withColumn('cos_minute', F.cos(2 * pi * df['minute'] / 60))\n",
    "df = df.withColumn('cos_hour', F.cos(2 * pi * df['hour'] / 24))\n",
    "\n",
    "df = df.drop(\"Start date\", \"Start station number\", \"Duration\", \"month\", \"hour\", \"minute\", \"day_of_week\", \"week_of_year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+-----------------+------------------+--------------------+-------------------+--------------------+-------------------+--------+---------------+-------------------+---------+------------------+--------+\n",
      "|Member type|            label|start_station_lat|start_station_long|     sin_day_of_week|   sin_week_of_year|           sin_month|         sin_minute|sin_hour|cos_day_of_week|   cos_week_of_year|cos_month|        cos_minute|cos_hour|\n",
      "+-----------+-----------------+-----------------+------------------+--------------------+-------------------+--------------------+-------------------+--------+---------------+-------------------+---------+------------------+--------+\n",
      "|     Casual|7.924072324923417|        38.890544|        -77.049379|-2.44929359829470...|0.05924062789371414|1.224646799147353...|0.10452846326765346|     0.0|            1.0|-0.9982437317643215|     -1.0|0.9945218953682733|     1.0|\n",
      "|     Casual| 7.92443418488756|        38.890544|        -77.049379|-2.44929359829470...|0.05924062789371414|1.224646799147353...|0.10452846326765346|     0.0|            1.0|-0.9982437317643215|     -1.0|0.9945218953682733|     1.0|\n",
      "|     Member| 6.53813982376767|        38.928893|         -77.03625|-2.44929359829470...|0.05924062789371414|1.224646799147353...|0.10452846326765346|     0.0|            1.0|-0.9982437317643215|     -1.0|0.9945218953682733|     1.0|\n",
      "+-----------+-----------------+-----------------+------------------+--------------------+-------------------+--------------------+-------------------+--------+---------------+-------------------+---------+------------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the categorical feature 'Member type'\n",
    "rider_indexer = StringIndexer(inputCol='Member type', outputCol='rider_idx')\n",
    "rider_encoder = OneHotEncoder(inputCol='rider_idx', outputCol='rider_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a VectorAssembler for all features\n",
    "vector = VectorAssembler(\n",
    "    inputCols=[\n",
    "        'start_station_lat',\n",
    "        'start_station_long',\n",
    "        'rider_enc',\n",
    "        'sin_day_of_week',\n",
    "        'cos_day_of_week',\n",
    "        'sin_week_of_year',\n",
    "        'cos_week_of_year',\n",
    "        'sin_month',\n",
    "        'cos_month',\n",
    "        'sin_minute',\n",
    "        'cos_minute',\n",
    "        'sin_hour',\n",
    "        'cos_hour',\n",
    "    ],\n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "# StandardScaler will scale all features\n",
    "scaler = StandardScaler(\n",
    "    inputCol='features', \n",
    "    outputCol='scaled_features'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestRegressor(featuresCol='scaled_features')\n",
    "glr = GeneralizedLinearRegression(\n",
    "    featuresCol='scaled_features'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        rider_indexer, \n",
    "        rider_encoder, \n",
    "        vector, \n",
    "        scaler, \n",
    "        glr\n",
    "    ]\n",
    ")\n",
    "\n",
    "evaluation = RegressionEvaluator()\n",
    "grid = ParamGridBuilder()\n",
    "grid = grid.addGrid(glr.maxIter, [25, 35])\n",
    "grid = grid.addGrid(glr.family, [\"gamma\", \"poisson\"])\n",
    "grid = grid.addGrid(glr.regParam, [0.0, 0.5])\n",
    "grid = grid.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=grid, \n",
    "    evaluator=evaluation,\n",
    "    numFolds=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([.7, .3])\n",
    "models = cv.fit(train)\n",
    "best = models.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = models.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_best_params(params: dict) -> dict:\n",
    "    best_params_as_dict = {}\n",
    "    for param, value in params.items():\n",
    "        param_name = param.name\n",
    "        best_params_as_dict[param_name] = value\n",
    "    return best_params_as_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_algo = best.stages[-1]\n",
    "extract_best_params(best_algo.extractParamMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
